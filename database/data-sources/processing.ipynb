{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data sources:\n",
    "\n",
    "https://www.kaggle.com/datasets/shuyangli94/food-com-recipes-and-user-interactions?select=RAW_recipes.csv\n",
    "\n",
    "https://www.kaggle.com/datasets/shuyangli94/foodcom-recipes-with-search-terms-and-tags\n",
    "\n",
    "https://www.kaggle.com/datasets/irkaal/foodcom-recipes-and-reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download all data sources and unpack then in src directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read cvs file \"PP_recipes.csv\" and print first 10 rows\n",
    "raw_recipes = pd.read_csv('src/RAW_recipes.csv')\n",
    "raw_recipes = raw_recipes[['id', 'minutes', 'submitted', 'tags']]\n",
    "raw_recipes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_with_ingredients = pd.read_csv('src/recipes_w_search_terms.csv')\n",
    "recipes_with_ingredients = recipes_with_ingredients[['id', 'name', 'ingredients_raw_str', 'ingredients', 'steps', 'description']]\n",
    "recipes_with_ingredients.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_big = pd.read_parquet('src/recipes_with_imgs.parquet', engine='fastparquet')\n",
    "print(recipes_big.columns)\n",
    "recipes_big = recipes_big[['RecipeId', 'AuthorId', 'AuthorName', 'ReviewCount']]\n",
    "recipes_big.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_tokenized = pd.read_csv('src/PP_recipes.csv')\n",
    "recipes_tokenized = recipes_tokenized[['id', 'calorie_level', 'ingredient_ids']]\n",
    "recipes_tokenized.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare recipes base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge interactions_count with recipes based in id\n",
    "recipes_full = pd.merge(raw_recipes, recipes_with_ingredients, left_on='id', right_on='id', how='left')\n",
    "# merge interactions_count with recipes based in id\n",
    "recipes_full = pd.merge(recipes_full, recipes_tokenized, left_on='id', right_on='id', how='left')\n",
    "# merge with recipes_big\n",
    "recipes_full = pd.merge(recipes_full, recipes_big, left_on='id', right_on='RecipeId', how='left')\n",
    "\n",
    "recipes_full = recipes_full.dropna(subset=['AuthorId', 'AuthorName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort recipes by review count and take top 1000\n",
    "base_recipes = recipes_full.sort_values(by=['ReviewCount'], ascending=False)\n",
    "base_recipes.dropna()\n",
    "\n",
    "# drop recipes where ingredient_ids are nan\n",
    "base_recipes = base_recipes.dropna(subset=['ingredient_ids'])\n",
    "base_recipes = base_recipes.head(5000)\n",
    "\n",
    "\n",
    "base_recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingredients table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = pd.read_pickle('src/ingr_map.pkl')\n",
    "\n",
    "# create new ingredients table data, that stores only processed and id columns off current ingredients data\n",
    "ingredients_processed = ingredients[['id', 'replaced']]\n",
    "ingredients_processed.columns = ['id', 'name']\n",
    "\n",
    "# remove repetitions in ingredients_processed\n",
    "ingredients_processed = ingredients_processed.drop_duplicates()\n",
    "# save processed ingredients to csv file\n",
    "ingredients_processed.to_csv('result/ingredients.csv', index=False)\n",
    "\n",
    "ingredients_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipes-ingredients table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "# create empty pandas dataframe\n",
    "recipes_ingredients = pd.DataFrame()\n",
    "\n",
    "to_drop = []\n",
    "for index, row in base_recipes.iterrows():\n",
    "    try:\n",
    "        ingredients_raw = ast.literal_eval(row['ingredients_raw_str'])\n",
    "        ingredients_ids = ast.literal_eval(row['ingredient_ids'])\n",
    "        ingredients_names = ast.literal_eval(row['ingredients'])\n",
    "    except:\n",
    "        to_drop.append(index)\n",
    "        continue\n",
    "\n",
    "    if len(ingredients_names) > len(ingredients_ids):\n",
    "        ingredients_names = ingredients_names[:len(ingredients_ids)]\n",
    "    elif len(ingredients_names) < len(ingredients_ids):\n",
    "        ingredients_ids = ingredients_ids[:len(ingredients_names)]\n",
    "\n",
    "    if len(ingredients_raw) > len(ingredients_names):\n",
    "        ingredients_raw = ingredients_raw[:len(ingredients_names)]\n",
    "    elif len(ingredients_raw) < len(ingredients_names):\n",
    "        ingredients_names = ingredients_names[:len(ingredients_raw)]\n",
    "    \n",
    "    ingredients_quantity = []\n",
    "    for ingredient_raw, ingredient_name in zip(ingredients_raw, ingredients_names):\n",
    "        if ingredient_name in ingredient_raw:\n",
    "            quantity = ingredient_raw.split(ingredient_name)[0].strip()\n",
    "            ingredients_quantity.append(quantity)\n",
    "        else:\n",
    "            ingredients_quantity.append('')\n",
    "    # create dataframe with names and id's \n",
    "    ingredients_array = pd.DataFrame({'ingredient_id': ingredients_ids, 'quantity': ingredients_quantity, })\n",
    "\n",
    "    # add row id column to tags_array\n",
    "    ingredients_array['recipe_id'] = row['id']\n",
    "\n",
    "    # add row to recipes_tags dataframe\n",
    "    recipes_ingredients = pd.concat([recipes_ingredients, ingredients_array], ignore_index=True)\n",
    "\n",
    "# drop recipes with index in to_drop\n",
    "base_recipes = base_recipes.drop(to_drop)\n",
    "\n",
    "# change the order of columns in recipes_ingredients\n",
    "recipes_ingredients = recipes_ingredients[['recipe_id', 'ingredient_id', 'quantity' ]]\n",
    "\n",
    "# drop duplicate rows, where recipe_id and ingredient_id are the same\n",
    "recipes_ingredients = recipes_ingredients.drop_duplicates(subset=['recipe_id', 'ingredient_id'])\n",
    "\n",
    "recipes_ingredients.to_csv('result/recipes_ingredients.csv', index=False)\n",
    "print(len(to_drop), len(base_recipes))\n",
    "recipes_ingredients.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tags table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forbidden_tags = ['time-to-make', 'course', 'main-ingredient', 'cuisine', 'preparation', \n",
    "'north-american', 'equipment', '4-hours-or-less', '5-ingredients-or-less', 'beef', 'crock-pot-slow-cooker',\n",
    " 'roast-beef', 'taste-mood', 'poultry', 'chicken', 'chicken-breasts', 'corn', 'southern-united-states',\n",
    "  'bananas', 'holiday-event', 'southwestern-united-states', 'apples', 'beans', 'eggs', 'beef-ribs',\n",
    "   'black-beans', 'brown-rice', 'refrigerator', 'tuna', 'grapes', 'tomatoes', 'salmon', 'pork']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "# create empty pandas dataframe\n",
    "tags = pd.DataFrame()\n",
    "\n",
    "# iterate for every row in recipes_with_interactions_1\n",
    "for index, row in base_recipes.iterrows():\n",
    "    tags_array = ast.literal_eval(row['tags'])\n",
    "    tags_array = filter(lambda x: x not in forbidden_tags, tags_array)\n",
    "    # add tags to tags dataframe\n",
    "    tags = pd.concat([tags, pd.DataFrame(tags_array)], ignore_index=True)\n",
    "\n",
    "# remove repetitions in tags\n",
    "tags = tags.drop_duplicates()\n",
    "# name first column in tags \"tag_name\"\n",
    "tags.columns = ['name']\n",
    "tags['id'] = tags.index\n",
    "\n",
    "tags = tags[['id', 'name']]\n",
    "# add id column to tags\n",
    "\n",
    "tags.to_csv('result/tags.csv', index=False)\n",
    "tags.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipes-tags table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty pandas dataframe\n",
    "recipes_tags = pd.DataFrame()\n",
    "\n",
    "# iterate for every row in recipes_with_interactions_1\n",
    "for index, row in base_recipes.iterrows():\n",
    "    tags_array = ast.literal_eval(row['tags'])\n",
    "    tags_array = filter(lambda x: x not in forbidden_tags, tags_array)\n",
    "\n",
    "    # find tag id for every tag name in tags_array\n",
    "    tags_ids = tags[tags['name'].isin(tags_array)]['id'].values\n",
    "\n",
    "    tags_ids_df = pd.DataFrame(tags_ids, columns=['tag_id'])\n",
    "\n",
    "    # add row id column to tags_array\n",
    "    tags_ids_df['recipe_id'] = row['id']\n",
    "\n",
    "    # add row to recipes_tags dataframe\n",
    "    recipes_tags = pd.concat([recipes_tags, tags_ids_df], ignore_index=True)\n",
    "\n",
    "# change the order of columns in recipes_tags\n",
    "recipes_tags = recipes_tags[['recipe_id', 'tag_id']]\n",
    "recipes_tags.to_csv('result/recipes_tags.csv', index=False)\n",
    "\n",
    "recipes_tags.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipes-steps table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_steps = pd.DataFrame()\n",
    "\n",
    "for index, row in base_recipes.iterrows():\n",
    "    steps = ast.literal_eval(row['steps'])\n",
    "    \n",
    "    # create dataframe with names and id's \n",
    "    steps = pd.DataFrame({'step_content': steps, 'step_number': range(1, len(steps) + 1)})\n",
    "\n",
    "    # add row id column to tags_array\n",
    "    steps['recipe_id'] = row['id']\n",
    "\n",
    "    # add row to recipes_tags dataframe\n",
    "    recipes_steps = pd.concat([recipes_steps, steps], ignore_index=True)\n",
    "\n",
    "# change the order of columns in recipes_ingredients\n",
    "recipes_steps = recipes_steps[['recipe_id', 'step_number', 'step_content']]\n",
    "\n",
    "recipes_steps.to_csv('result/recipes_steps.csv', index=False)\n",
    "recipes_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Users table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from passlib.context import CryptContext\n",
    "pwd_context = CryptContext(schemes=[\"bcrypt\"], deprecated=\"auto\")\n",
    "\n",
    "# find distinct contributor_id in recipes_table\n",
    "users = base_recipes[['AuthorId', 'AuthorName']].drop_duplicates()\n",
    "\n",
    "# change the name of the first column \"id\"\n",
    "users.columns = ['id', 'username']\n",
    "users['id'] = users['id'].astype(int)\n",
    "\n",
    "users['username'] = users['username'].str.replace(\" \", \"\")\n",
    "# add email column which is equal to id\n",
    "users['email'] = users['username'].str.lower() + '@unknown.com'\n",
    "users['hashed_password'] =  pwd_context.hash('password123')\n",
    "users['last_login'] =  '2023-01-20'\n",
    "\n",
    "users.to_csv('result/users.csv', index=False)\n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipes table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_table = base_recipes.drop(['steps', 'ingredients', 'ingredient_ids', 'ingredients_raw_str', 'tags', 'RecipeId', 'AuthorName'], axis=1)\n",
    "\n",
    "# change column name call ReviewCount to reactions\n",
    "recipes_table = recipes_table.rename(columns={'ReviewCount': 'likes', 'submitted': 'date_added', 'name': 'title', 'AuthorId': 'contributor_id'})\n",
    "recipes_table = recipes_table[['id', 'contributor_id', 'title', 'minutes', 'description',  'date_added', 'likes', 'calorie_level']]\n",
    "\n",
    "recipes_table['description'] = recipes_table['description'].str.capitalize()\n",
    "recipes_table['contributor_id'] = recipes_table['contributor_id'].astype(int)\n",
    "recipes_table['calorie_level'] = recipes_table['calorie_level'].astype(int)\n",
    "recipes_table['likes'] = recipes_table['likes'].astype(int)\n",
    "\n",
    "recipes_table.to_csv('result/recipes.csv', index=False)\n",
    "\n",
    "recipes_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
